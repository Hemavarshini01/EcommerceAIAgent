# ğŸ›’ Ecommerce AI Agent

A local, privacy-first **AI question-answering API** over your sales data, powered by open-source LLMs (like Gemma with Ollama).

---

## ğŸ“¦ Project Structure

```
ECOMMERCE_AI_AGENT/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ ad_sales_metrics.csv
â”‚   â”œâ”€â”€ all_metrics.db
â”‚   â”œâ”€â”€ eligibility.csv
â”‚   â””â”€â”€ total_sales_metrics.csv
â”œ
â”œâ”€â”€ app.py
â”œâ”€â”€ merge_to_sql.py
â”œâ”€â”€ ollama
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## ğŸš€ Setup & Usage

### 1. Prerequisites

- Python 3.8+
- [Ollama](https://ollama.com/) installed (for local LLM inference)
- All your data CSVs inside the `data/` folder

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Merge CSVs and Build Database

```bash
python merge_to_sql.py
```
- This creates or updates `data/all_metrics.db` from your CSVs.

### 4. Pull & Run the LLM Model

In a new terminal:

```bash
ollama pull gemma:2b
ollama run gemma:2b
```
_(Keep this terminal running.)_

### 5. Start the API Server

In another terminal:

```bash
uvicorn app:app --reload
```

### 6. Ask Questions (Natural Language â†’ SQL â†’ Answer)

Use [http://localhost:8000/docs](http://localhost:8000/docs) for interactive testing, or try:

```bash
curl -X POST "http://localhost:8000/ask" \
  -H "Content-Type: application/json" \
  -d "{\"question\":\"What is the total sales of the company?\"}"
```

### 7. Get Answers With Plots

For questions that should produce a plot (e.g. "Show daily total sales over time"):

```bash
curl -X POST "http://localhost:8000/ask_with_plot" \
  -H "Content-Type: application/json" \
  -d "{\"question\": \"Show daily total sales over time\"}"
```

If `"plot_url": "/plot"` is in the response, view [http://localhost:8000/plot](http://localhost:8000/plot) in your browser.

---

## ğŸ“Š How Plotting Works

If your SQL result includes fields `date` and `total_sales`, the API automatically generates a line plot and serves it at `/plot`.

---

## âš¡ Files Overview

- **data/**: All input CSVs and the generated SQLite database.
- **app.py**: FastAPI app (LLM â†’ SQL â†’ responses/plots).
- **merge_to_sql.py**: Merges your CSVs into the database.
- **requirements.txt**: Python dependencies.
- **README.md**: Project instructions.
- **.env**: _(Optional)_ For environment variables.
- **ollama**: _(Optional label/folder for local Ollama config)_

---

## ğŸ›¡ï¸ Notes & Troubleshooting

- Ensure Ollama and the model are running (**keep ollama run window open**).
- If plotting, ensure your `date` column is parseable (ideally `YYYY-MM-DD` format).
- For dataset or model changes, re-run the relevant steps above.
- All LLM calls and plots run **fully locally**â€”your data never leaves your machine.

---

## ğŸ“š Further Customizations

- Expand with new plot types by editing `app.py`.
- Switch to `Mistral`, `Phi-3`, or `Llama 3` by pulling with Ollama and changing the model string in `app.py`.

---

## ğŸ¤– Get Help

If you run into issues, check logs in the terminal windows or [Ollama docs](https://ollama.com/). For project-specific issues, consult this READMEâ€™s Troubleshooting section.

---
